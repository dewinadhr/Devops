
Overview
The objective of this lab is to familiarize yourself with the specific capabilities of Cloud Monitoring to monitor GKE cluster infrastructure, Istio, and applications deployed on this infrastructure.

What you'll do
1. Create a GKE cluster

2. Deploy a microservices application to it

3. Define latency and error SLIs and SLOs for it

4. Configure Cloud Monitoring to monitor your SLIs

5. Deploy a breaking change to the application and use Cloud Monitoring to troubleshoot and resolve the issues that result

6. Validate that your resolution addresses the SLO violation

What you'll learn
1. How to deploy a microservices application on an existing GKE cluster

2. How to select appropriate SLIs/SLOs for an application

3. How to implement SLIs using Cloud Monitoring features

4. How to use Cloud Trace, Cloud Profiler, and Cloud Debugger to identify software issues

===============================

gcloud auth list

gcloud config list project

*Set the zone in gcloud:

gcloud config set compute/zone us-west1-b

*Set the project ID:
export PROJECT_ID=$(gcloud info --format='value(config.project)')

*Verify that the cluster named shop-cluster has been created:
gcloud container clusters list

--If your cluster status says PROVISIONING, wait a moment and run the command above again. Repeat until the status is RUNNING.

While you're waiting, set up your Cloud Monitoring workspace to monitor the application on your cluster.

*Create a Monitoring workspace

In the Cloud Console, click Navigation menu > Monitoring.

Check your cluster
Go back to Cloud Shell. Once your cluster has RUNNING status, get the cluster credentials:

gcloud container clusters get-credentials shop-cluster --zone us-west1-b
(Output)

kubectl get nodes

Run the following to clone the repo:
git clone https://github.com/GoogleCloudPlatform/training-data-analyst

Create a soft link to your working directory:
ln -s ~/training-data-analyst/blogs/microservices-demo-1 ~/microservices-demo-1

Download and install skaffold:
curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/v0.36.0/skaffold-linux-amd64 && chmod +x skaffold && sudo mv skaffold /usr/local/bin
Install the app using skaffold:

cd microservices-demo-1

skaffold run

kubectl get pods

<<Deploy application>>

Get the external IP of the application:
export EXTERNAL_IP=$(kubectl get service frontend-external | awk 'BEGIN { cnt=0; } { cnt+=1; if (cnt > 1) print $4; }')

Finally, confirm that the app is up and running:
curl -o /dev/null -s -w "%{http_code}\n"  http://$EXTERNAL_IP
Note: You may need to run this command a second time if you get a 500 error. You should see a 200 as confirmation.

Download the source and put the code in Cloud Source Repositories:
./setup_csr.sh
Now that the application has been deployed, set up monitoring for the application.

Resources
Microservices Demo Application

Skaffold

Develop Sample SLOs and SLIs
Before implementing any monitoring, review the introduction to the chapter on Service Level Objectives from the Site Reliability Engineering book:

"It's impossible to manage a service correctly, let alone well, without understanding which behaviors really matter for that service and how to measure and evaluate those behaviors. To this end, we would like to define and deliver a given level of service to our users, whether they use an internal API or a public product.

"We use intuition, experience, and an understanding of what users want to define service level indicators (SLIs), objectives (SLOs), and agreements (SLAs). These measurements describe basic properties of metrics that matter, what values we want those metrics to have, and how we'll react if we can't provide the expected service. Ultimately, choosing appropriate metrics helps to drive the right action if something goes wrong, and also gives an SRE team confidence that a service is healthy.

"An SLI is a service level indicator—a carefully defined quantitative measure of some aspect of the level of service that is provided.

"Most services consider request latency — how long it takes to return a response to a request — as a key SLI. Other common SLIs include the error rate, often expressed as a fraction of all requests received, and system throughput, typically measured in requests per second. Another kind of SLI important to SREs is availability, or the fraction of the time that a service is usable. It is often defined in terms of the fraction of well-formed requests that succeed. Durability — the likelihood that data is be retained over a long period of time — is equally important for data storage systems. The measurements are often aggregated: i.e., raw data is collected over a measurement window and then turned into a rate, average, or percentile."

Now that you have established a basic understanding, define the SLIs and SLOs for your application. Given that the application itself serves end user ecommerce traffic, it's going to be very important that user experience remains constant and that performance is good. Monitor SLIs for request latency, error rate, throughput, and availability.

Application Architecture
f818a68bd5b98622.png

It's impossible to develop SLIs without understanding how the application is built. Details are in the original repository, but for this lab, it suffices to understand that:

Users access the application through the Frontend.

Purchases are handled by CheckoutService.

CheckoutService depends on CurrencyService to handle conversions.

Other services such as RecommendationService, ProductCatalogService, and Adservice are used to provide the frontend with content needed to render the page.

Service Level Indicators and Objectives
The following SLIs and SLOs are selected based on the end-user experience and the theoretical impact to users and business objectives.

SLI

Metric

Description

SLO

Request latency

Front end latency

Measures how long a user is waiting for the page to load. A high latency typically correlates to a negative user experience

99% of requests from the previous 60 minute period are services in under 3 seconds

Error rate

Front end error rate

Measures the error rate experienced by users. A high error rate likely indicates an issue.

0 Errors in the previous 60 minute period

Checkout error rate

Measures the error rate experienced by other services calling the checkout service. A high error rate likely indicates an issue.

0 Errors in the previous 60 minute period

Currency Service error rate

Measures the error rate experienced by other services calling the currency service. A high error rate likely indicates an issue.

0 Errors in the previous 60 minute period

Availability

Front end success rate

Measures the rate of successful requests as a way to determine the availability of the service. A low success rate likely indicates that users are having a poor experience.

99% of requests are successful over the previous 60 minute period

Configure Latency SLI
Create alerting policies for each of your SLOs. The metrics you are interested in are already being collected.

Front End Latency
In the Console, still in the Cloud Monitoirng window (Navigation menu > Monitoring), click Alerting from the left menu, then click Create Policy.

Click Add Condition. Next, specify the metric and condition to use to trigger the Alerting Policy.

The condition lets you know when you're experiencing performance issues that are impacting user experience. As described in the Service Level Indicators and Objectives table above, use the 99th percentile front end latency as the SLI.
Add the following into the Find resource type and metric field then select the following from the dropdown menu:

custom.googleapis.com/opencensus/grpc.io/client/roundtrip_latency
If the metric is not found, wait a minute and then try again.

1st_metric.png

In the Resource Type type in Global, then select it.

Click into the Filter field and select opencensus_task. Click the first default Value, then click Apply.

Next, set the Aggregator to 99th percentile.

Your screen should look like this:

stackdriver_latency_policy2.png

Next, in the Configuration area, set the options as follows:

Condition triggers if Any time series violates
Condition: is above
Threshold: 500
For: Most recent value
stackdriver_latency_alert.png

Click Add.

Click Next. Skip the Who should be notified? step and click Next.

Now, name the alerting policy as Latency Policy in the Alert name field.

Click Save.

You've configured Cloud Monitoring for your frontend latency SLI!

Click Check my progress to verify the objective.
Configure Latency SLI

Configure Availability SLI
Next, monitor your service availability by creating another Alerting Policy.

Frontend Availability
Start by monitoring the error rate for the frontend service, since that’s where user experience is going to be most directly impacted. As discussed above, you’re going to consider any failures observed to be an SLO violation. Create an alerting policy that triggers an incident if any failures are observed.

An easy way to trigger on a particular failure is to use log-based metrics.

In the Console, select Navigation menu > Logging > Logs Explorer.

Click on the OPTIONS drop down and select Go back to the Legacy Logs Viewer.

Configure the filter as follows:

In Resource type (first dropdown menu) select Kubernetes Container

In Log Level (third dropdown menu) select ERROR

In the filter search bar enter the following filter and hit enter button:

label:k8s-pod/app:"currencyservice"
log_filter.png

Note: You won't see any results on the page because the service is running correctly. You will make a change soon to change this result.
Click Create Metric.

Name the metric Error_Rate_SLI and click Create Metric to save the log-based metric:

log_metric.png

In the Logs-based Metrics window, scroll to the bottom to see your new metric listed in User-defined Metrics. Now create an alert for this metric by clicking the 3 dots at the end of the row, then select Create alert from metric.

stackdriver_log_metric_sli.png

Notice the resource type and metric have already been filled in.

Refresh your browser if the Metric is displaying "invalid".

If you receive a permissions error and are unable to view your metrics resources after refreshing, please ensure that you are signed in to your temporary student account in the Console and that you have signed out of any other Google account accessed in your browser.
Name the condition Error Rate SLI.

Click the Show Advanced Options link and set the following:

Aligner: rate
In Configuration, set your Threshold to 0.5 for 1 minute.

Then Save the condition and click Next.

Skip the Who should be notified? step and click Next.

Now, name the alerting policy as Error Rate SLI in the Alert name field.

Click Save.

As expected, there are no failures, and your application is currently meeting its availability SLO!

Click Check my progress to verify the objective.
Configure Availability SLI

Deploy new release
Now that you have configured SLI monitoring, you're ready to measure the impact of application changes on user experience. See what happens when you deploy a new release of the application.

Next you'll modify the Kubernetes manifests for the services which have new releases, then run skaffold to deploy the application again.

Update YAML files
If necessary, re-activate Cloud Shell, and then launch the Code Editor in Cloud Shell by clicking Open Editor:

d91b3d47091e7176.png

Open the microservices-demo-1 folder, then open the kubernetes-manifests folder within it.

Open the kubernetes_manifests/recommendationservice.yaml, on line 31 replace with the following:

You will be updating these 3 files:

kubernetes_manifests/recommendationservice.yaml
kubernetes_manifests/currencyservice.yaml
kubernetes_manifests/frontend.yaml
You will be changing the image to rel013019, and adding a line: imagePullPolicy: Always.

For example, the original version of the recommendationservice.yaml file:

be6fd76ca59d64db.png

How it should look after making the update:

caf0b2c0654e5973.png

Update the other two files in the same way:

kubernetes_manifests/currencyservice.yaml (line 31)
kubernetes_manifests/frontend.yaml (line 30)
Save and close each file when you're finished. Now you're ready to deploy the new version!

Deploy New Version
In Cloud Shell, update the deployment to deploy the new container image:

skaffold run
Validate that there are new versions of services running:

kubectl get pods
(Output)

NAME                                     READY     STATUS    RESTARTS   AGE
adservice-55f94cfd9c-4lvml               1/1       Running   0          17d
cartservice-6f4946f9b8-6wtff             1/1       Running   197        17d
checkoutservice-5688779d8c-l6crl         1/1       Running   0          17d
currencyservice-665d6f4569-b4sbm         1/1       Running   0          1m
emailservice-684c89bcb8-h48sq            1/1       Running   0          17d
frontend-5f889fc7bb-wvfvv                1/1       Running   0          1m
loadgenerator-6d646566db-p422w           1/1       Running   0          17d
paymentservice-858d89d64c-hmpkg          1/1       Running   0          17d
productcatalogservice-bcd85cb5-d6xp4     1/1       Running   0          17d
recommendationservice-57cb4559f9-bdgj7   1/1       Running   0          1m
redis-cart-9b864d47f-c9xc6               1/1       Running   0          17d
shippingservice-5948f9fb5c-vndcp         1/1       Running   0          17d
Click Check my progress to verify the objective.
Deploy new release

Send some data
Now that the application is running, go look at what you have deployed.

In the Console, navigate to Kubernetes Engine > Services & Ingress. Look for the frontend-external service and click on the Endpoint URL.

Once on the Hipster Shop website, click on a Buy and/or Add to Cart for a couple of items to send some traffic. Stay on the website for about 60 seconds to generate enough latency data.

Latency SLO Violation - Find the Problem
In this exercise you use Cloud Monitoring Application Performance Management (APM) tools to identify and resolve an issue causing poor application latency.

First, see if everything is still OK with the application after deploying the new version.

Return to the Cloud Monitoring window in the Console (Navigation menu > Monitoring). Click the autorefresh arrows in the top ribbon so you will always be looking at the latest information.

A Latency Policy incident appears shortly if it hasn't already, please wait a few minutes to see it show up.

Stackdriver_latency_policy.png

To learn more about what's going on, click Alerting in the left menu, and then click the alert in the Incidents section. You may need to click on the Acknowledge Incident to see that the alert happened.

The best way to analyze latency issues is by using Trace. Click on Navigation menu > Trace.

The initial overview is useful, but you need to get to the next level of detail. Click Trace List on the left menu.

Click Auto Reload. Notice the scatter plot at the top of the page and that, around the time of the alert, there are a large number of outlier requests.

Wait a minute or two, to gather data, then click on one of the outlier traces to see the specifics about what is going on.

6a05ee60a0daa87.png

Notice the Span name (which represents the service or function that is being called) is either /cart/ or /cart/checkout/.

To help understand how this trace compares with similar ones prior to the issue, look at the "Recv./cart" Summary in the lower left for all the cart operations and look for similar traces.

At the top, set the time period to 1 hour so that it includes traces that occurred before the issue.

64c6982957db838c.png

Click on an example trace from before the issue occurred

9b446892a7770fd8.png

Notice that in this similar trace ListRecommendations was only called once. However, after the most recent deploy, ListRecommendations is being called many times per request, causing significant additional latency.

You can conclude that the issue with these outliers is caused by multiple calls to ListRecommendations.

Deploy Change to Address Latency
In order to address the latency issue that the last release created, you need to roll out another version that fixes the broken code. Modify the Kubernetes manifests for the services that contained the broken code.

To deploy a fix, return to the Cloud Shell tab where the Source Code Editor should still be open. You'll modify the following files:

kubernetes_manifests/recommendationservice.yaml
kubernetes_manifests/frontend.yaml
Modify the image tag rel013019 with rel013019fix so the image should look like this:

      containers:
      - name: server
        image: gcr.io/accl-19-dev/frontend:rel013019fix
        imagePullPolicy: Always
5602175997ba2cd0.png

Save the files.

Return to the Cloud Shell prompt and redeploy the images with the fixes in them:

skaffold run
Click Check my progress to verify the objective.
Deploy Change to Address Latency

Validate Fix
Now that you've rolled back the breaking change, verify that your application is back to a healthy state.

Return to Metrics Explorer (Navigation menu > Monitoring > Metrics Explorer).

In the search field, enter latency and click on custom.googleapis.com/opencensus/grpc.io/client/roundtrip_latency.

185dd877b3d55bf.png

Select Global as a resource type. Click here link in the Aggregator field.

Change the chart type to Line. You should see a chart that shows an immediate decrease in latency (and if you don't, wait a minute).

69ba9bd7c87115f9.png

Now, see if the incidents are resolved. Return to the Monitoring Overview.

You should notice two things - you no longer have an incident, and there are events letting you know that the incident has been resolved. Again, if you don't see an Incident resolved message, wait a couple of minutes.

Your monitoring was able to correctly identify a change that caused user experience (as measured by latency) to degrade, you were able to identify the root cause, and you've rolled back the breaking change! In the next section, see how Cloud Monitoring can help you resolve an issue with availability.

Error Rate SLO Violation - Find the Problem
In this exercise you use Cloud Monitoring Application Performance Management tools (APM) to troubleshoot an issue causing ERRORs in your application violating your error budget.

Click Alerting in Monitoring.

Look for a Error Rate SLI incident, and click the Acknowledge incident to learn more about what's going on. Incidents can take several minutes to be confirmed and listed as an incident. If an incident has not yet arrived, you can skip the Incident step below.

You can see that the currencyservice pod is logging significantly more errors than it was previously.

Acknowledge the incident so that no further notification escalation takes place.

For an alert like this there are many places to start, but the easiest is Cloud Error Reporting. Select Navigation menu > Error Reporting.

Notice the Open Error Reporting incidents with a recent spike in occurrences. Click on the Error: Conversion is Zero to learn more about the error in question.

error_reporting1.png.png

Look at the Stack Trace sample on the right. Here you can see what specific calls were related to the error.

error_reporting3.png

Click on the lowest call showing here: /usr/src/app/server/js:131

This loads you into Cloud Debugger. In the top bar verify the currency service is selected.

dcb90f0fce431ec.png

Next, select the source code that is running from Cloud Source Repositories

97ba51694adc967b.png

Select your source with:

Repository: apm-qwiklabs-demo
Tagged version or branch: APM-Troubleshooting-Demo-2
Then click Select Source.

In the left hand menu browse to /src/currencyservice/server.js.

267a2773a8fbce8.png

Scroll down to around line 155 which is the function where the exception was thrown. You can see the logline Conversion is Zero that was referenced in error reporting.

6bc6f0c7f2f436e1.png fff6e7e964cf3ac6.png

From the above code snippet you see this error is logged when result.units < 0. To troubleshoot this issue you'll use Snapshots to inspect the variables as the application progresses.

Make sure you have selected Snapshot in the top right:

97347c0fd561f8a3.png

Then click on the line number (155) you want to snapshot:

774be2495268d15d.png

For this exercise take snapshots at line 155, 141, and 149. Add additional snapshot points wherever you feel appropriate. The system takes a variable snapshot the next time that code is executed. While the application is waiting for the code to be executed next you can see a "Waiting for snapshot to hit...." notice.

When the snapshot is complete, the right hand pane displays the variables for that given snapshot.

74a796c219d2ad97.png

Notice the Variable and Call Stack information. This information can provide extremely deep understanding of the path you code is taking including the variables and structures that exist as it takes that path, all without restarting the application or changing any code.

Click result to inspect all 3 snapshots finishing on line 155. Remember the error is triggered when result.units is NOT > 0. Inspecting the variables you can see that result.units = NaN (meaning ‘not a number'). This is the issue that is causing the error.

cf9717dbcf09659a.png

At this point you can conclude that the error is caused by a bug in the convert (or child) functions which sets the result.units to 0 resulting in a 0.00 price tag for the item being converted. Your troubleshooting along with the snapshot information and logs is a solid diagnosis of the issue.

So what is the bug that has caused this problem? From the code, result.units is set by the line 144 from euros, which was set in line 137 by operating on from.units

bef885a4cb6d54f7.png

Inspecting the snapshots euros.units is also NaN, however, from.units is a valid number. Thus the issue happened when converting from.units to euros.

1cbc42017f0e4e76.png

You can conclude that the root cause is a bug in how from.units is converted into euros.units on line 137 8 is passed into Data[] which is actually a key value mapping of currency units (like EUR) into exchange rates. The corrected line 138 would use from.to_currency (aka USD) instead of from.units (aka 8).

e79ad235feef0dcf.png

At this point you have determined the cause of the bug and can make the appropriate change. Based on the timing of the alert, this could have been caused by the latest deployment.

See if the previous branch "Master" had this code error on line 137.

Go back to the Console and inspect the code using Cloud Source Repositories (in the console menu under Tools).

Open the apm-qwiklabs-demo repository and select the master branch.

Browse on the left hand side to src > currencyservice > server.js. Notice on line 137 the proper dividend: data[from.currency_code] is used.

13375108606a76d7.png

You have confirmation this bug was introduced in the latest push. To mitigate this problem you need to roll back to the previous version.

Deploy Change to Address Error Rate
In order to fix this issue, you'll need to deploy a fix to your application. To do that, you'll need to modify the Kubernetes manifest for the service that contained the broken code.

Deploy Fix
Return to Cloud Shell and in the Source Code Editor open the currencyservice.yaml file in the kubernetes_manifests folder.

78698b11c80697f.png

Replace the image tag rel013019 with rel013019fix so the image should look like this:

      containers:
      - name: server
        image: gcr.io/accl-19-dev/currencyservice:rel013019fix
        imagePullPolicy: Always
Close the file to save it and return to the Cloud Shell prompt.

Redeploy the image with the fix in it:

skaffold run
Click Check my progress to verify the objective.
Deploy Change to Address Error Rate

Validate Fix
Now that you've rolled back the breaking change, verify that the application is back to a healthy state.

As before, start by verifying that your incident is resolved. Go to the Alerting window in the Console and verify that the error rate incident is resolved.

Next, return to Error Reporting and click Auto Reload. Open the error previously observed, and verify that it is no longer occurring (the timeline should show no further occurrences since the last deployment):

error_reporting.png

Congratulations - your monitoring was able to correctly identify a change that caused user experience (as measured by application errors) to degrade, you were able to identify the root cause, and you've rolled back the breaking change!

Move on to the next section to learn about how you can optimize resource utilization using Cloud Monitoring.

Application optimization with Cloud Monitoring APM
In this exercise use Cloud Monitoring Application Performance Management tools (APM) to identify opportunities for improvement that helps your application run faster and use less compute resources.

In this scenario, the Director of Cloud Operations is disappointed with the recent rise in compute costs. Specifically, the currencyservice service is using more CPU than expected based on the usage of the system.

Your team has been tasked with finding optimization opportunities. Use APM tools to analyze the service, and ensure your team's efforts are focused on the right areas of the application.

From the Console, open Profiler from the left hand menu.

1607c72d45a41947.png

Change the Timespan in the upper right to 30 minutes. If there is no data, wait a minute or 2 for the data to populate.

NOTE: Profiler takes a random sample of calls to build an aggregate call stack. If you don't see the data you expect, it's because not enough time has elapsed during this lab, and you completed it faster than expected. Feel free to use the screenshots below during the excercise.

In the filter options select the frontend service, the CPU time Profile type.

profiler.png

Profiler takes random sample profiles of the system and combines the data to show you what functions are using the most resources. The flame graph below shows the function calls grouped by their use of the resource (in this case CPU) where the X-axis is the amount of CPU and the Y-axis shows parent child relationships.

profiler1.pngIn this case the majority of the CPU is used by the ServeHTTP call on the left hand side. Click on this call to drill into the cause.

profiler2.png

The expanded view shows almost half of this is caused by viewCartHandler, which in turn is mostly caused by getRecommendations.

The opportunity here is in the getRecommendations and in turn getProduct. Thinking back to your earlier exercise, remember that the recommendation service and getProduct were being called often in a loop due to an error in retry logic. The resolution for that issue will likely decrease compute cost by as much as 20%.

Congratul
